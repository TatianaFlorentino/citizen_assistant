# -*- coding: utf-8 -*-
"""citizen_assistant.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/gist/TatianaFlorentino/8e8d9b165eccc078caec6edfcd125d26/citizen_assistant.ipynb
"""

# 1️⃣ Instalar pacotes essenciais
!pip install streamlit pandas openai langchain --quiet

# 2️⃣ Criar CSV de FAQ exemplo
import pandas as pd

faq_data = {
    "Pergunta": [
        "Como criar um cadastro?",
        "Como consultar um protocolo?",
        "Como alterar meus dados?",
        "Como gerar relatórios?"
    ],
    "Resposta": [
        "Para criar um cadastro, clique em 'Novo Cadastro', preencha os campos obrigatórios e clique em 'Salvar'.",
        "Acesse 'Consulta de Protocolos', informe o número do protocolo e clique em 'Pesquisar'.",
        "Entre na seção 'Meus Dados' e clique em 'Editar'. Salve as alterações ao finalizar.",
        "Vá até 'Relatórios', selecione o período e o tipo de relatório, e clique em 'Gerar'."
    ]
}

faq = pd.DataFrame(faq_data)
faq.to_csv("faq.csv", index=False)
print("FAQ criada!")

# 3️⃣ Código do Citizen Support Assistant
assistant_code = """
import pandas as pd
import streamlit as st
from langchain.prompts import PromptTemplate
from langchain.llms import OpenAI
from langchain.chains import LLMChain

# Carregar FAQ
faq = pd.read_csv("faq.csv")

# Criar prompt template
template = '''
Você é um assistente que responde dúvidas de cidadãos sobre um sistema público.
Use as respostas do FAQ abaixo para responder de forma clara e simples:

FAQ:
{faq_data}

Pergunta do usuário: {user_question}
Resposta:
'''

prompt = PromptTemplate(input_variables=["faq_data", "user_question"], template=template)
llm = OpenAI(temperature=0)
chain = LLMChain(llm=llm, prompt=prompt)

def responder_pergunta(user_question):
    faq_text = "\\n".join([f"Q: {q} A: {a}" for q, a in zip(faq["Pergunta"], faq["Resposta"])])
    return chain.run(faq_data=faq_text, user_question=user_question)

# Interface Streamlit
st.title("Citizen Support Assistant – Manual Interativo")
st.write("Pergunte algo sobre o sistema e receba uma resposta rápida!")

user_input = st.text_input("Digite sua pergunta:")

if user_input:
    resposta = responder_pergunta(user_input)
    st.write(resposta)
"""

with open("app.py", "w") as f:
    f.write(assistant_code)
print("app.py criado!")

# 4️⃣ Rodar Streamlit

!pip install pyngrok
from pyngrok import ngrok

ngrok.set_auth_token("34g4BogHtaIAM5Em6WNFalKreMr_3HK8R9Ln8LUXiNqFKWcjX")
public_url = ngrok.connect(port=8501)
print(public_url)

